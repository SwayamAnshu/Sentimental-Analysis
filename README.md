# Sentiment Analysis using Deep Learning (SNN, CNN, LSTM with GloVe Embeddings)

1. This project implements a sentiment analysis system on a labeled dataset of tweets. The models used include:
- Simple Neural Network (SNN)
- Convolutional Neural Network (CNN)
- Long Short-Term Memory (LSTM)

We utilize pre-trained GloVe word embeddings for word representation and analyze the model performance using metrics like accuracy, loss curves, confusion matrix, and classification reports.

---

## ğŸ“ Project Structure

.
â”œâ”€â”€ data/

â”‚ â””â”€â”€ file.csv # Labeled tweet dataset

â”œâ”€â”€ embeddings/
â”‚ â””â”€â”€ glove.6B.100d.txt # Pretrained GloVe vectors

â”œâ”€â”€ embedding_matrix.csv # Extracted embedding matrix for model training

â”œâ”€â”€ sentiment_analysis.py # Main training and evaluation script

â”œâ”€â”€ requirements.txt # Required Python packages

â””â”€â”€ README.md # Project documentation


---

## ğŸ§  Model Architectures

- **SNN (Simple Neural Network)**: Embedding â†’ Flatten â†’ Dense â†’ Dropout â†’ Output
- **CNN**: Embedding â†’ Conv1D â†’ GlobalMaxPooling1D â†’ Dense â†’ Dropout â†’ Output
- **LSTM**: Embedding â†’ LSTM â†’ Dense â†’ Dropout â†’ Output

---

## ğŸ“Š Dataset

- The dataset `file.csv` contains two columns:
  - `tweets`: Text data.
  - `labels`: One of `good`, `neutral`, or `bad`.

Label encoding:
- `good` â†’ 1
- `neutral` â†’ 2
- `bad` â†’ 0

---

## ğŸ”§ Preprocessing Steps

- Lowercasing text
- Removing HTML tags, URLs, punctuation, and stopwords
- Tokenization and padding to fixed length (100)
- Word embeddings using 100-dimensional GloVe vectors

---

## ğŸš€ Getting Started

### 1. Clone the repository

git clone https://github.com/yourusername/sentiment-analysis-glove.git
cd sentiment-analysis-glove

2. Install dependencies
   pip install -r requirements.txt

3. Add Data and Embeddings
   -> Place your file.csv under the data/ directory.
   -> Download GloVe embeddings and place glove.6B.100d.txt under embeddings/.
4. Run the script
   python sentiment_analysis.py
   
ğŸ“ˆ Results
Each model's performance is evaluated using:

Accuracy and Loss curves (training vs validation)

Confusion Matrix

Precision, Recall, and F1-score (classification report)

ğŸ“Œ Notes
GloVe vectors are loaded from glove.6B.100d.txt

The model saves the best weights using ModelCheckpoint during training

ğŸ“œ License
This project is licensed under the MIT License.

ğŸ”„ Project Workflow Diagram -->

Raw Tweets (CSV)
      â”‚
      â–¼
[ Preprocessing ]
   - Clean text
   - Remove stopwords
   - Tokenize & Pad
   - Label Encoding
      â”‚
      â–¼
[ GloVe Embedding Matrix ]
      â”‚
      â–¼
[ Choose Model ]
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚    SNN     â”‚    CNN     â”‚   LSTM     â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
[ Model Training & Validation ]
      â”‚
      â–¼
[ Evaluation ]
   - Accuracy & Loss Graphs
   - Confusion Matrix
   - Classification Report


ğŸ§   Model Architecture Diagrams
1. Simple Neural Network (SNN)

  Input (100 tokens)
  
      â”‚
      
[ Embedding Layer (GloVe) ]

      â”‚
      
[ Flatten ]

      â”‚
      
[ Dense (128) + ReLU ]

      â”‚
      
[ Dropout (0.5) ]

      â”‚
      
[ Dense (3) + Softmax ]


2. Convolutional Neural Network (CNN)

  Input (100 tokens)
  
      â”‚
      
[ Embedding Layer (GloVe) ]

      â”‚
      
[ Conv1D (128 filters, kernel=5) ]

      â”‚
      
[ GlobalMaxPooling1D ]

      â”‚
      
[ Dense (128) + ReLU ]

      â”‚
      
[ Dropout (0.5) ]

      â”‚
      
[ Dense (3) + Softmax ]


3. Long Short-Term Memory (LSTM)

  Input (100 tokens)
  
      â”‚
      
[ Embedding Layer (GloVe) ]

      â”‚
      
[ LSTM (128 units) ]

      â”‚
      
[ Dense (128) + ReLU ]

      â”‚
      
[ Dropout (0.5) ]

      â”‚
      
[ Dense (3) + Softmax ]





ğŸš€ Full Project Workflow
1. Data Collection & Loading
Source: train.csv and test.csv containing tweet text and sentiment labels.

Format:

Columns: text, label

Labels: 0 (negative), 1 (neutral), 2 (positive)

2. Data Preprocessing
Text Cleaning:

Remove HTML tags

Remove special characters and punctuation

Convert text to lowercase

Tokenization:

Use Tokenizer from Keras to convert text into integer sequences.

Padding:

Pad sequences to a maximum length (e.g., 100 tokens).

Label Encoding:

Convert categorical labels (0,1,2) into one-hot encoded vectors.

Split:

Split dataset into train and validation sets.

3. Embedding Layer
Pre-trained Embeddings:

Load GloVe (Global Vectors) embeddings (glove.6B.100d.txt).

Embedding Matrix:

Create an embedding matrix matching each word index to its GloVe vector.

Embedding Layer:

Use this matrix in a non-trainable Keras Embedding layer.

4. Model Building
Choose one or multiple architectures:

âœ… Simple Neural Network (SNN)
Embedding â†’ Flatten â†’ Dense â†’ Dropout â†’ Dense (Softmax)

âœ… Convolutional Neural Network (CNN)
Embedding â†’ Conv1D â†’ GlobalMaxPooling1D â†’ Dense â†’ Dropout â†’ Dense (Softmax)

âœ… Long Short-Term Memory (LSTM)
Embedding â†’ LSTM â†’ Dense â†’ Dropout â†’ Dense (Softmax)

5. Model Compilation
Loss: categorical_crossentropy

Optimizer: adam

Metrics: accuracy

6. Training
Train model using the fit() function.

Use EarlyStopping or ModelCheckpoint if needed.

7. Evaluation
Evaluate model on validation and test sets.

Metrics:

Accuracy

Precision, Recall, F1-Score (via classification_report)

Confusion Matrix

Visualizations:

Training vs Validation Accuracy/Loss

Confusion Matrix Heatmap

8. Inference
Load saved model.

Pass new tweet(s) through the preprocessing pipeline.

Predict sentiment: negative, neutral, or positive.

9. Export & Deployment (Optional)
Save model using .h5 or .pb

Create an API using Flask or FastAPI

Deploy on a server or frontend app




ğŸ§­ Summary Diagram (Workflow Outline)

               +----------------+
               |  Load Dataset  |
               +-------+--------+
                       |
               +-------v--------+
               | Preprocess Text|
               +-------+--------+
                       |
               +-------v--------+
               | Tokenize & Pad |
               +-------+--------+
                       |
               +-------v--------+
               | Encode Labels  |
               +-------+--------+
                       |
               +-------v------------------------+
               | Load GloVe & Create Embedding  |
               +-------+------------------------+
                       |
               +-------v-----------------------------+
               | Choose Model: SNN / CNN / LSTM      |
               +-------+-----------------------------+
                       |
               +-------v--------+
               |   Train Model  |
               +-------+--------+
                       |
               +-------v--------+
               |  Evaluate Model|
               +-------+--------+
                       |
               +-------v--------+
               | Make Predictions|
               +----------------+

